{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T05:23:17.887574Z",
     "start_time": "2019-11-06T05:23:17.871325Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T04:14:21.134660Z",
     "start_time": "2019-11-06T04:14:21.115235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "この画像データのラベルは5です\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MNISTデータの前処理\n",
    "X = mnist.data / 255  \n",
    "# 正解ラベル\n",
    "y = mnist.target\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X[0].reshape(28, 28), cmap='gray')\n",
    "print(\"この画像データのラベルは{}です\".format(y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T04:13:22.224330Z",
     "start_time": "2019-11-06T04:12:35.360Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataLoderの作成\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# データを訓練とテストのために、6:1に分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=1/7, random_state=0)\n",
    "\n",
    "# 5-2. データのフォーマットを変換：PyTorchでの形式 = [画像数，チャネル数，高さ，幅]\n",
    "X_train = X_train.reshape(60000, 1, 28, 28)\n",
    "X_test = X_test.reshape(10000, 1, 28 ,28)\n",
    "\n",
    "y_train = y_train.astype(\"float64\")\n",
    "y_test = y_test.astype(\"float64\")\n",
    "\n",
    "# データをPyTorchのTensorに変換\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# データとラベルをセットにしたDatasetを作成\n",
    "ds_train = TensorDataset(X_train, y_train)\n",
    "ds_test = TensorDataset(X_test, y_test)\n",
    "\n",
    "# データセットのミニバッチサイズを指定した、Dataloaderを作成\n",
    "loader_train = DataLoader(ds_train, batch_size=32, shuffle=True)\n",
    "loader_test = DataLoader(ds_test,batch_size=32,  shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# 外部モジュールの変更を反映\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T04:13:22.234119Z",
     "start_time": "2019-11-06T04:12:47.063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPP_Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=672, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 畳み込みニューラルネットワークの設定\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from spp_layer import spatial_pyramid_pool\n",
    "\n",
    "num_layer = 2                   # 畳み込み層の数\n",
    "num_filters = [16, 32]          # 各畳み込み層のフィルタ数\n",
    "mid_units = 100                 # 全結合層のユニット数\n",
    "\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "kernel = 3\n",
    "#dropout_prob = 0.0\n",
    "\n",
    "class SPP_Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SPP_Net, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1, num_filters[0], 3)\n",
    "    self.conv2 = nn.Conv2d(num_filters[0], num_filters[1], 3)\n",
    "    \n",
    "    self.output_num = [4,2,1]\n",
    "    \n",
    "    self.fc1 = nn.Linear(in_features= num_filters[1]*sum([16,4,1]), out_features=mid_units)     \n",
    "    #self.fc1 = nn.Linear(in_features= num_filters[1]*5*5, out_features=mid_units) \n",
    "    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n",
    "        \n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    \n",
    "    # 最後のpooling層のみSPP層に変更\n",
    "    x = self.conv2(x)\n",
    "    x = F.relu(spatial_pyramid_pool(self,x,self.output_num))\n",
    "\n",
    "    x = x.view(x.size(0),-1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "spp_model = SPP_Net()\n",
    "print(spp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 畳み込みニューラルネットワークの設定\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "num_layer = 2                   # 畳み込み層の数\n",
    "num_filters = [16, 32]          # 各畳み込み層のフィルタ数\n",
    "mid_units = 100                 # 全結合層のユニット数\n",
    "\n",
    "in_height = 28\n",
    "in_width = 28\n",
    "kernel = 3\n",
    "#dropout_prob = 0.0\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1, num_filters[0], 3)\n",
    "    self.conv2 = nn.Conv2d(num_filters[0], num_filters[1], 3)\n",
    "    \n",
    "    self.output_num = [4,2,1]\n",
    "    \n",
    "    #self.fc1 = nn.Linear(in_features= num_filters[1]*11*11, out_features=mid_units)     \n",
    "    self.fc1 = nn.Linear(in_features= num_filters[1]*5*5, out_features=mid_units) \n",
    "    self.fc2 = nn.Linear(in_features=mid_units, out_features=10)\n",
    "        \n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "            \n",
    "    #print(x.size())\n",
    "    \n",
    "    x = x.view(x.size(0),-1)\n",
    "    #print(x.size())\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 誤差関数と最適化手法の設定\n",
    " \n",
    "from torch import optim\n",
    " \n",
    "# 誤差関数の設定\n",
    "loss_fn = nn.CrossEntropyLoss()  # 変数名にはcriterionも使われる\n",
    " \n",
    "# 重みを学習する際の最適化手法の選択\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer_spp = optim.Adam(spp_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 学習と推論の設定\n",
    "# 学習1回でやることを定義します\n",
    "# Chainerのtraining.Trainer()に対応するものはない\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def train(epoch, pooling_method):\n",
    "    if pooling_method == \"SPP\":\n",
    "        spp_model.train()\n",
    "        # ネットワークを学習モードに切り替える\n",
    "        # データローダーから1ミニバッチずつ取り出して計算する\n",
    "        for data, target in loader_train:\n",
    "            data, target = Variable(data), Variable(target)  # 微分可能に変換\n",
    "            optimizer_spp.zero_grad()  # 一度計算された勾配結果を0にリセット\n",
    "            output = spp_model(data)  # 入力dataをinputし、出力を求める\n",
    "            loss = loss_fn(output, target)  # 出力と訓練データの正解との誤差を求める\n",
    "            loss.backward()  # 誤差のバックプロパゲーションを求める\n",
    "            optimizer_spp.step()  # バックプロパゲーションの値で重みを更新する\n",
    "    else:\n",
    "        model.train()\n",
    "        for data, target in loader_train:\n",
    "            data, target = Variable(data), Variable(target)  # 微分可能に変換\n",
    "            optimizer.zero_grad()  # 一度計算された勾配結果を0にリセット\n",
    "            output = model(data)    \n",
    "            loss = loss_fn(output, target)  # 出力と訓練データの正解との誤差を求める\n",
    "            loss.backward()  # 誤差のバックプロパゲーションを求める\n",
    "            optimizer.step()  # バックプロパゲーションの値で重みを更新する\n",
    "\n",
    "    print(\"epoch{}：終了\\n\".format(epoch))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(pooling_method):\n",
    "    # ネットワークを推論モードに切り替える\n",
    "    if pooling_method == \"SPP\":\n",
    "        spp_model.eval()\n",
    "    else:\n",
    "        model.eval()\n",
    "        \n",
    "    correct = 0\n",
    "    # データローダーから1ミニバッチずつ取り出して計算する\n",
    "    for data, target in loader_test:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        if pooling_method == \"SPP\":\n",
    "            output = spp_model(data)  \n",
    "        else:\n",
    "            output = model(data)    \n",
    "        \n",
    "        # 推論する\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # 出力ラベルを求める\n",
    "        correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        loss = loss_fn(output, target) \n",
    "        # 正解と一緒だったらカウントアップ\n",
    "        # 正解率を出力\n",
    "        data_num = len(loader_test.dataset)\n",
    "        \n",
    "    # データの総数\n",
    "    print('\\nテストデータの正解率: {}/{} ({:.0f}%)\\n'.format(correct, data_num, 100. * correct / data_num))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "max pooling\n",
      "\n",
      "テストデータの正解率: 1278/10000 (13%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.2906, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習なしにテストデータで推論\n",
    "test('MAX')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1037/10000 (10%)\n",
      "\n",
      "epoch1：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1037/10000 (10%)\n",
      "\n",
      "epoch2：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1037/10000 (10%)\n",
      "\n",
      "epoch3：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1037/10000 (10%)\n",
      "\n",
      "epoch4：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1037/10000 (10%)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-e96b53780221>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpooling_method\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooling_method\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-0f89a1abfffd>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, pooling_method)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 微分可能に変換\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 一度計算された勾配結果を0にリセット\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 出力と訓練データの正解との誤差を求める\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 誤差のバックプロパゲーションを求める\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-3813b6ca78a8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     return torch.max_pool2d(\n\u001b[1;32m--> 488\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "train_loss_list_spp = []\n",
    "test_loss_list_spp = []\n",
    "\n",
    "pooling_method = ['MAX','SPP']\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(epoch, pooling_method[0])\n",
    "    test_loss = test(pooling_method[0])\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    test_loss_list.append(test_loss)\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(epoch, pooling_method[1])\n",
    "    test_loss = test(pooling_method[1])\n",
    "    \n",
    "    train_loss_list_spp.append(train_loss)\n",
    "    test_loss_list_spp.append(test_loss)\n",
    "    \n",
    "\n",
    "# save the training model\n",
    "np.save('train_loss_list.npy', np.array(train_loss_list))\n",
    "np.save('test_loss_list.npy', np.array(test_loss_list))\n",
    "np.save('train_loss_list_spp.npy', np.array(train_loss_list))\n",
    "np.save('test_loss_list_spp.npy', np.array(test_loss_list))\n",
    "torch.save(model.state_dict(), 'vae.pth')\n",
    "torch.save(spp_model.state_dict(), 'vae_spp.pth')\n",
    "    \n",
    "#loss_list = np.load('{}/loss_list.npy'.format(out_dir))\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_list, label=\"Max pooling\")\n",
    "plt.plot(train_loss_list_spp, label=\"Spatial Pyramid Pooling\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"train loss\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(test_loss_list, label=\"Max pooling\")\n",
    "plt.plot(test_loss_list_spp, label=\"Spatial Pyramid Pooling\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(\"test loss\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1278/10000 (13%)\n",
      "\n",
      "epoch1：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1278/10000 (13%)\n",
      "\n",
      "epoch2：終了\n",
      "\n",
      "\n",
      "テストデータの正解率: 1278/10000 (13%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# max-pooling\n",
    "# 60000のデータに3エポック学習を実行する\n",
    "for epoch in range(3):\n",
    "    train(epoch,\"MAX\")\n",
    "    test(\"MAX\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "321.583px",
    "left": "467.785px",
    "right": "20px",
    "top": "301px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
